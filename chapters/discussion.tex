\chapter{Discussion and Conclusions}\label{ch:discussion}

\lang is neither perfect nor complete:
the nature of the syntactic model requires that inductives live in a universe
higher than that in which their corresponding unsized types would live,
and it's missing features such as an infinite size and coinductives.
In this chapter, I discuss some of these shortcomings
and give some possible directions for future work based on them.

\section{The Infinite Size} \label{sec:infinity}

In prior sized type systems, the infinite size\index{infinite size} $\infty$ is applied to sized inductive types
to represent a ``full'' inductive type encompassing that inductive at all sizes,
which essentially corresponds to the usual unsized inductive.
Whereas an inductive of some size $s$ can be thought of as the type of elements
with at most $s$ many layers of constructors,
the full inductive can be thought of as the type of elements with any number of layers of constructors.

The infinite size is characterized by its subsizing behaviour:
$\subsize*{s}{\infty}$ holds for \emph{any} $s$.
This includes its own successor, \ie $\subsize*{\sss{\infty}}{\infty}$,
leading to non--well-founded sequences of strictly ``decreasing'' sizes:
$\dots < \infty < \infty < \infty$.
Naturally, there's no way to model the infinite size as an element of $\SizeT$
given that I've shown that $\SizeT$s \emph{are} well founded.
If there were, then it'd be possible to prove an inconsistency.
Let $\inftyT$ be the translation of $\infty$,
and let $\inftyltinfty$ be the translation of $\subsize*{\sss{\infty}}{\infty}$.
\begin{align*}
&\LetT{\tg{{\neg}wf\inftyT}}{\arrT*{\app{\AccT}{\inftyT}}{\botT}}{\funT{\mathit{acc}}{\app{\AccT}{\inftyT}}{\matchT*{\mathit{acc}}{\app{\accT}{p} \RightarrowT \app{p}{\inftyT}{\inftyltinfty}}}} \\
&\LetT{\tg{false}}{\botT}{\app{\tg{{\neg}wf\inftyT}}{(\app{\accessible}{\inftyT})}}
\end{align*}

In set-theoretic models of sized type systems with an infinite size,
sizes are modelled as set-theoretic (transfinite) ordinals,
the infinite size isn't modelled as a single ordinal;
instead, for each use of the infinite size,
its set-theoretic interpretation is an ordinal that is ``large enough'' in that context.
For instance, the interpretation of the infinite size of $\N{\infty}$
is the first limit ordinal $\omega$.

This strategy doesn't adapt well to \lang with its size abstractions and syntactic model\index{syntactic model},
since it requires a non-local translation of sizes.
For instance, given the size application $\App{e}{\infty}$,
what $\infty$ translates to would hypothetically depend on what $e$ translates to,
and likely require further static analysis of $\compile{e}$ beyond a simple translation
over typing derivations.

Since the motivation for having the infinite size is specifically for representing full inductives,
one alternative could be to define the full inductive separately
and provide functions to and from the corresponding sized inductive,
such as the following for $\W*$.
\begin{align*}
& \data{\App{\app{\W*}{(\annot{A}{\Type{i}})}{(\annot{B}{\arr*{A}{\Type{i}}})}}{\infty}}{\Type{i+1}} \\
& \quad \annot{\constr{sup\infty}}{\arr{x}{A}{\arr*{(\arr*{\app{B}{x}}{\app{\App{\W*}{\infty}}{A}{B}})}{\App{\app{\W*}{A}{B}}{\infty}}}}
\end{align*}

Defining a function from $\W{x}{A}{B}{s}$ to $\W{x}{A}{B}{\infty}$ is trivial,
since we're discarding size information.
What about going from $\W{x}{A}{B}{\infty}$ to $\W{x}{A}{B}{s}$?
What should $s$ be?
The size algebra could be augmented to be able to represent transfinite ordinals
so that $s$ is again a size that is ``large enough'',
but we can hardly expect programmers to manipulate ordinals,
and I conjecture that we would lose any hope of deciding $\subsize*{}{}$
without any user intervention.

The key insight is that what's important about an element of a full inductive
isn't its precise size and depth of constructors,
but merely that it has \emph{some} unknown size.
Another alternative to the infinite size, then, could be to represent a full inductive
as an existentially-quantified sized inductive,
\ie $\Pairtype{\alpha}{\N{\alpha}}$ and $\Pairtype{\alpha}{\W{x}{A}{B}{\alpha}}$.
We've already seen existential sizes in action: they're in the return types of $\qsort$ and $\msort$.

There is still a limitation similar to that in \cref{sec:examples:limitations}
when trying to represent the constructors of full inductives.
For $\Pairtype{\alpha}{\W{x}{A}{B}{\alpha}}$, we need a ``constructor'' of the following type.
\begin{align*}
\annot{\const{sup'}}{\arr{x}{A}{\arr*{(\arr*{B}{\Pairtype{\alpha}{\W{x}{A}{B}{\alpha}}})}{\Pairtype{\alpha}{\W{x}{A}{B}{\alpha}}}}}
\end{align*}
All we need is a function
$$\annot{\const{ac}}{\arr{x}{A}{\arr*{(\arr*{B}{\Pairtype{\alpha}{\W{x}{A}{B}{\alpha}}})}{\Pairtype{\alpha}{(\arr*{B}{\W{x}{A}{B}{\alpha}})}}}}$$
and we're good to go.
\begin{align*}
\app{\const{sup'}}{x}{f} =
\unpair*{\alpha}{f'}{\app{\const{ac}}{x}{f}}{\Pair{\sss{\alpha}}{\sup{x}{A}{B}{\sss{\alpha}}{\alpha}{x}{f'}}}
\end{align*}

Unfortunately, as the name might suggest,
$\const{ac}$ is an instance of the axiom of choice\punctstack{,}%
\footnote{The ``choice'' made here is the existentially-quantified size in the consequent:
the axiom asserts that there's always a way to choose a size such that
all of the well-founded trees returned have that size.}
which for weak existentials\index{weak dependent pair} (whose elements we can't project out)
is nonconstructive,
so there's no hope of implementing $\const{ac}$.
However, if we take weak existentials as a primitive of \lang
rather than being defined as an encoding,
and model them by strong dependent pairs in \CICE,
then the translation of $\const{ac}$ \emph{can} be implemented as a function,
also making use of the limit operator.
In other words, the syntactic model\index{syntactic model} justifies the axiom $\const{ac}$ in the source.
The mechanization of $\compile{\const{ac}}$ in Agda and Coq are given in
\cref{app:mechanization:agda:W} and \cref{app:mechanization:coq:W}, respectively.

Nevertheless, $\const{ac}$ remains a noncomputing axiom
unless the size algebra is augmented to include a limit operator
and size expressions consequently treated as regular terms.
There is no way to represent generalized full inductives as
sized inductives existentially quantified by sizes
and faithfully define their constructors without losing either
decidability of subsizing from exposing the underlying ordinal representation of sizes,
or canonicity from the inclusion of a noncomputing axiom.
Representing ordinary full inductives (namely naturals) this way,
however, has been previously explored~\citep{guarded, modal-sizes}.

\section{Universe Levels of Inductives} \label{sec:universe-levels}

The universes in which the type of natural numbers and W types in \lang live
are, in a sense, one level\index{universe level} higher than is usually expected;
their typing rules are reproduced below.
$\N*$ is typically in $\Type{0}$,
while $\W*$ is typically in $U$ rather than $\axioms{U}$.
\begin{mathpar}
\inferrule[\rref*{nat}]{
  \wf{\Phi}{\Gamma} \\
  \wf{\Phi}{s}
}{
  \infer{\Phi; \Gamma}{\N{s}}{\Type{1}}
}
\and
\inferrule[\rref*{wft}]{
  \wf{\Phi}{s} \\
  \infer{\Phi; \Gamma}{\sigma}{U} \\\\
  \infer{\Phi; \Gamma, \annot{x}{\sigma}}{\tau}{U}
}{
  \infer{\Phi; \Gamma}{\W{x}{\sigma}{\tau}{s}}{\axioms{U}}
}
\end{mathpar}

This is due to how the translation is defined:
$\NatT$ and $\WT$ have a $\SizeT$ as parameter,
the $\limT$ operator quantifies over the type of the domain of its function argument,
and that type must be ``large'' enough to accommodate the correct type.
For $\app{\WT}{\sigmaT}{\tauT}{\sT}$,
the domain is $\app{\tauT}{\aT}$ for some $\aT$\punctstack{,}%
\footnote{For generalized inductives, given a recursive argument in the form of a function,
the domain of $\limT$ should encompass the domain of that function.}
as is the case for the definition of $\compile{\const{ac}}$,
so if its universe is $\TypeT{\iT}$,
then the universe of the type of $\sT$ must be $\TypeT{\tg{i+1}}$,
according to the definition of $\SizeT$, reproduced below.

\begin{align*}
&\dataT{\SizeT}{\TypeT{\tg{i+1}}} \\
&\quad \annotT{\sucT}{\arrT*{\SizeT}{\SizeT}} \\
&\quad \annotT{\limT}{\funtypeT{A}{\TypeT{\iT}}{\arrT*{(\arrT*{A}{\SizeT})}{\SizeT}}}
\end{align*}

This is a nonnegotiable condition:
defining $\SizeT$ to be in the same universe as that which $\limT$ quantifies over
leads to $\szltT$ no longer being well founded,
since in this hypothetical scenario $\SizeT$ itself could be applied to $\limT$
to define an $\inftyT$ size.
\begin{align*}
&\LetT{\inftyT}{\SizeT}{\app{\limT}{\SizeT}{(\funT{\xT}{\SizeT}{\xT})}} \\
&\LetT{\inftyltinfty}{\inftyT \szltT \inftyT}{\app{\coconeT}{\SizeT}{(\app{\sucT}{\inftyT})}{(\funT{\xT}{\SizeT}{\xT})}{(\app{\sucT}{\inftyT})}{(\app{\reflleq}{(\app{\sucT}{\inftyT})})}}
\end{align*}

One way to ``shrink'' the universe of $\SizeT$, so to speak,
could be to parametrize it over the type over which $\limT$ currently quantifies over,
yielding the following inductive definition.
\begin{align*}
&\dataT{\app{\SizeT}{(\annotT{A}{\TypeT{\iT}})}}{\TypeT{\iT}} \\
&\quad \annotT{\sucT}{\arrT*{\SizeT}{\SizeT}} \\
&\quad \annotT{\limT}{\arrT*{(\arrT*{A}{\SizeT})}{\SizeT}}
\end{align*}

The problem with this alternative is that for $\app{\WT}{\sigmaT}{\tauT}$,
the parameter of its size parameter would be $\app{\tauT}{\aT}$,
where $\annotT{\aT}{\sigmaT}$ is the third formal argument to its constructor $\supT$,
but this argument is only part of the constructor, not the type.
The intuition is that the parametrized $\SizeT$ is too restrictive
and there aren't ``enough'' sizes to cover all well-founded trees of any particular type.

In a sense, it's reasonable to expect that $\SizeT$ needs to live in a larger universe.
The r\^ole of $\SizeT$ is to represent all of the possible sizes of a given full inductive,
so we would expect $\SizeT$ to be just as large as the inductive itself.
Aside from situations where the inductive is impredicative\index{impredicativity}, \ie in $\PropT$,
parametrizing over $\SizeT$ then necessarily requires moving up a universe
so that it's not essentially quantifying over itself.

If having inductive types in the correct universe were more important than
the potential expressibility of infinitude,
we could eliminate $\limT$ altogether and model sizes as ordinary naturals.
Then $\SizeT$ would live in $\Type{0}$, $\NatT$ and $\WT$ would live in the correct universes,
as well as $\N*$ and $\W*$.
Although this would affect the judgements of both \lang and \CICE,
this wouldn't affect the proofs, since the changes are the same for both languages.
However, this does mean giving up $\const{ac}$
and likely any hope of defining any infinitary constructs like $\const{\omega}$
when using this model.

\section{Streams and Coinductives}

Dual to inductive types, coinductive types allow for constructing
potentially infinitely large elements in a principled manner,
and are present in many proof assistants such as Coq, Agda, and Idris.
Conventionally, while fixpoints are guarded by destructors\index{guardedness}
and destruct elements of inductives by recurring only on syntactically smaller elements,
cofixpoints are guarded by constructors and occur only as a syntactic argument to a constructor~\citep{guard}.
Since coinductives aren't present in pCIC\index{Calculus of Inductive Constructions!Predicative \textasciitilde},
upon which \CICE is based, I don't include them in \lang either,
as they would lack a translation in the syntactic model.
Nevertheless, we can speculate on how they might appear and interact with sizes.
Here, I define the classic example of coinductive streams,
composed of a head element and a tail stream.
\begin{mathpar}
\inferrule[\rlabel*{stream}]{
  \wf{\Phi}{s} \\
  \infer{\Phi; \Gamma}{\tau}{U}
}{
  \infer{\Phi; \Gamma}{\Stream{\tau}{s}}{U}
}
\and
\inferrule[\rlabel*{hd}]{
  \infer{\Phi; \Gamma}{e}{\Stream{\tau}{s}}
}{
  \infer{\Phi; \Gamma}{\shd{e}}{\tau}
}
\and
\inferrule[\rlabel*{tl}]{
  \infer{\Phi; \Gamma}{e}{\Stream{\tau}{s}}
}{
  \infer{\Phi; \Gamma}{\stl{e}}{\Funtype<{\alpha}{s}{\Stream{\tau}{\alpha}}}
}
\and
\inferrule[\rlabel*{scons}]{
  \infer{\Phi; \Gamma}{e_1}{\tau} \\
  \infer{\Phi, \bound{\alpha}{s}; \Gamma}{e_2}{\Stream{\tau}{\alpha}}
}{
  \infer{\Phi; \Gamma}{\scons{\alpha}{s}{e_1}{\alpha}{s}{e_2}}{\Stream{\tau}{s}}
}
\and
\inferrule[\rlabel*{cofix}]{
  \infer{\Phi, \alpha; \Gamma}{\sigma}{U} \\
  \fresh{\beta} \\
  \check{\Phi, \alpha; \Gamma, \annot{f}{\Funtype<{\beta}{\alpha}{\subst{\sigma}{\alpha}{\beta}}}}{e}{\sigma}
}{
  \infer{\Phi; \Gamma}{\cofix{f}{\alpha}{\sigma}{e}}{\Funtype{\alpha}{\sigma}}
}
\end{mathpar}

Just as the size of an inductive informally indicates at most how many layers of constructors its elements contain,
the size of a coinductive informally indicates \emph{at least} how many layers,
and in the case of $\app{\Stream*}{A}$, at least how many elements of $A$ it contains.
Of course, streams may contain an infinite number of elements,
so the analogy works better in the relative sense:
if a stream contains at least $s$ elements,
then its tail must contain at least $\bound{\alpha}{s}$, strictly fewer, elements.
The reduction rules of streams, omitted here, operate as expected:
$\shd{}$ projects out the head and $\stl{}$ projects out the tail.

To actually construct infinite streams, we need cofixpoint expressions.
The natural correspondence of guardedness\index{guardedness} in sized types
is that cofixpoint bodies must construct coinductives larger than
their own occurrences inside the body,
which coincides with the structure of \rref{fix}.
Cofixpoints also reduce when applied to a size that has some subsize,
just like fixpoints.
Interestingly, this suggests that cofixpoints might also be translated in the syntactic model
to well-founded induction\index{well-founded induction} on sizes despite constructing a coinductive type.

\clearpage % TODO: clearpage
With cofixpoints, we can then construct an infinite stream of some single element.
Let $A$ in the definitions to follow be some type.
\begin{align*}
& \Let{\dup}{\arr*{A}{\Funtype{\alpha}{\Stream{A}{\alpha}}}}{\\
& \quad \fun{a}{A}{\cofix{\dup*}{\alpha}{\Stream{A}{\alpha}}{\\
& \qquad \scons{\beta}{\alpha}{a}{\beta}{\alpha}{\App{\dup*}{\beta}}}}}
\end{align*}

Notice that the stream produced has \emph{any} size,
which can be interpreted as having ``at least'' any number of elements---a
truly infinite stream.
More generally, a coinductive universally quantified by size corresponds to a full coinductive,
dual to a inductive existentially quantified by a size corresponding to a full inductive.

We can manipulate sized streams as expected,
such as taking only the odd elements of a stream
or interleaving two streams by alternation.
\begin{align*}
& \Let{\odds}{\Funtype{\alpha}{\arr*{(\Funtype{\beta}{\Stream{A}{\beta}})}{\Stream{A}{\alpha}}}}{ \\
& \quad \cofix{\odds*}{\alpha}{\arr*{(\Funtype{\beta}{\Stream{A}{\beta}})}{\Stream{A}{\alpha}}}{ \\
& \qquad \fun{s}{\Funtype{\beta}{\Stream{A}{\beta}}}{\scons{\beta}{\alpha}{\shd{(\App{s}{\alpha})}}{\beta}{\alpha}{\app{\App{\odds*}{\beta}}{(\Fun{\gamma}{\App{\stl{(\App{\stl{(\App{s}{\sss{\sss{\gamma}}})}}{\sss{\gamma}})}}{\gamma}})}}}}} \\
\hfill \\
& \Let{\interleave}{\Funtype{\alpha}{\arr*{\Stream{A}{\alpha}}{\Stream{A}{\alpha}}{\Stream{A}{\alpha}}}}{ \\
& \quad \cofix{\interleave*}{\alpha}{\arr*{\Stream{A}{\alpha}}{\Stream{A}{\alpha}}{\Stream{A}{\alpha}}}{ \\
& \qquad \fun{s_1}{\Stream{A}{\alpha}}{\fun{s_2}{\Stream{A}{\alpha}}{\scons{\beta}{\alpha}{\shd{s_1}}{\beta}{\alpha}{ \\
& \qquad \quad \scons{\gamma}{\beta}{\shd{s_2}}{\gamma}{\beta}{\app{\App{\interleave*}{\alpha}}{(\App{\stl{s_1}}{\gamma})}{(\App{\stl{s_2}}{\gamma})}}}}}}}
\end{align*}

Just as with lists, we can write size-preserving functions on streams
and use them to define cofixpoints that would otherwise not pass syntactic guard checking.
One common example from Haskell is defining a stream of Fibonacci numbers using,
in our case, a size-preserving zipping function.
Suppose we have a function $\annot{f}{\arr*{A}{A}{A}}$ and some element $\annot{a}{A}$.
(For the actual Fibonacci numbers, $A$ would be the naturals, $f$ would be addition, and $a$ would be 1.)
\begin{align*}
& \Let{\zip}{\Funtype{\alpha}{\arr*{\Stream{A}{\alpha}}{\Stream{A}{\alpha}}{\Stream{A}{\alpha}}}}{ \\
& \quad \cofix{\zip*}{\alpha}{\arr*{\Stream{A}{\alpha}}{\Stream{A}{\alpha}}{\Stream{A}{\alpha}}}{ \\
& \qquad \fun{s_1}{\Stream{A}{\alpha}}{\fun{s_2}{\Stream{A}{\alpha}}{ \\
& \qquad \quad \scons{\beta}{\alpha}{\app{f}{\shd{s_1}}{\shd{s_2}}}{\beta}{\alpha}{\app{\App{\zip*}{\beta}}{(\App{\stl{s_1}}{\beta})}{(\App{\stl{s_2}}{\beta})}}}}}}
\end{align*}

\begin{align*}
& \Let{\fibs}{\Funtype{\alpha}{\Stream{A}{\alpha}}}{ \\
& \quad \cofix{\fibs*}{\alpha}{\Stream{A}{\alpha}}{ \\
& \qquad \scons{\beta}{\alpha}{a}{\beta}{\alpha}{\scons{\gamma}{\beta}{a}{\gamma}{\beta}{\app{\App{\zip}{\gamma}}{(\App{\fibs*}{\gamma})}{(\App{\stl{(\App{\fibs*}{\beta})}}{\gamma})}}}}}
\end{align*}

Coinductive types in general can be implemented as record definitions
just as inductive types can be implemented as data definitions.
However, sized coinductives in Agda's standard library are implemented
in terms of a single coinductive $\Thunk{F}{s}$ record%
\footnote{See \textsf{Codata.Sized.Thunk} from the Agda standard library, URL \url{https://agda.github.io/agda-stdlib/Codata.Sized.Thunk.html}.}
with sized parameter $F$ and size $s$,
and all other coinductives are implemented as nested inductives,
where occurrences of the type in its constructors' types are wrapped around a $\Thunk*$.
\begin{mathpar}
\inferrule[\rlabel*{thunk}]{
  \wf{\Phi}{s} \\
  \infer{\Phi; \Gamma}{F}{\Funtype{\alpha}{U}}
}{
  \infer{\Phi; \Gamma}{\Thunk{F}{s}}{U}
}
\and
\inferrule[\rlabel*{force}]{
  \infer{\Phi; \Gamma}{e}{\Thunk{F}{s}}
}{
  \infer{\Phi; \Gamma}{\force{e}}{\Funtype<{\alpha}{s}{\App{F}{\alpha}}}
}
\and
\inferrule[\rlabel*{think}]{
  \infer{\Phi, \bound{\alpha}{s}; \Gamma}{e}{\App{F}{\alpha}}
}{
  \infer{\Phi; \Gamma}{\thunk{\alpha}{s}{e}}{\Thunk{F}{s}}
}
\end{mathpar}

This alternate technique is equally expressive,
since it allows encoding M types, the dual of W types, not just streams.
\begin{align*}
& \data{\Stream{(\annot{A}{\Type{i}})}{\alpha}}{\Type{i+1}} \\
& \quad \annot{\scons*}{\arr*{A}{\Thunk{(\app{\Stream*}{A})}{\alpha}}{\Stream{A}{\alpha}}} \\
\hfill \\
& \data{\App{\app{\M*}{(\annot{A}{\Type{i}})}{(\annot{B}{\arr*{A}{\Type{i}}})}}{\alpha}}{\Type{i+1}} \\
& \quad \annot{\inf*}{\arr{a}{A}{\arr*{(\arr*{\app{B}{a}}{\Thunk{(\app{\M*}{A}{B})}{\alpha}})}{\App{\app{\M*}{A}{B}}{\alpha}}}}
\end{align*}

\section{Designing for Syntactic Modelling}

Choosing to use a syntactic model imposes some constraints on the design
of the source and target languages, as well as on the proof architecture.
Most notably, proof of correctness of syntactic models proceed
by induction on the source derivations,
so \lang uses untyped conversion to avoid a dependency between typing and definitional equality,
which would otherwise require a large and complex mutually inductive proof of type preservation.

Strictly speaking, such a proof would still be possible,
since the compositionality lemmas are merely up to syntactic equality.
If they were instead up to typed equivalence
(as is the case for the translations in \citet{wjb}),
then the base cases would fail:
to show
$\defeq{\compile{\Phi}, \compile{\Gamma}}{\yT}{\yT}{\compile{\tau}}$
via \rref{equiv-refl} for instance,
$\type{\compile{\Phi}, \compile{\Gamma}}{\yT}{\compile{\tau}}$
would be required,
but this can't be constructed even from
$\type{\Phi; \Gamma}{y}{\tau}$
as it's not a premise and therefore the mutual type preservation induction hypothesis can't be applied.
Still, I use untyped conversion to avoid any other potential complications with the mutual induction.

On the other hand, induction isn't done on the derivations of the target,
but since equality reflection is needed for translation-specific reasons,
\CICE uses typed equivalence instead to avoid the inconsistency and loss of subject equivalence
arising from reflecting propositional equality into transitive, untyped conversion,
as detailed in \cref{sec:target}.

Due to the incongruity between untyped conversion in the source and typed equivalence in the target,
the na\"ive proof attempts at preservation would be missing crucial typing information
to construct the target derivations, especially for equivalence.
This is why, in all of the preservation lemmas, well-typedness of the translated terms
are required as premises, essentially replacing what would've been mutual or circular appeals
to type preservation with just the right amount of typing information.

Quite unexpectedly, this also has an effect on whether conversion
in the source is declarative or algorithmic.
If it were declarative like \CICE's equivalence, with no reduction rules or their closures,
then transitivity of subtyping would need to be an explicit rule rather than a theorem.
But in preservation of subtyping, we need well-typedness of all translated terms---%
where would we derive the well-typedness of the middle term arising from the premises
of such a transitivity rule?
There's no ``subject subtyping'' as there is for subject reduction, and indeed,
$\subtype{\mt; \mt}{\Type{1}}{\App{(\fix{f}{\alpha}{\N{\alpha}}{\Type{2}})}{\sss{\circ}}}$
holds while the right-hand side, which is convertible to $\Type{2}$, isn't even well typed.

So simply by deciding on a syntactic model into an extensional type theory,
definitional equality in the source must be untyped and algorithmic,
while in the target it must be typed,
lest we create headaches for ourselves with these complex yet avoidable issues.

These consequences have further effects on the design of the source syntax,
particularly concerning type annotations, if we also take into account
the other required metatheoretical properties.
Proving subject reduction in the case of $\delta$-reduction requires that
definitions in the environment have type annotations;
otherwise, even if $\Gamma = (\define*{x}{e}), (\annot{x}{\tau})$ were well formed,
we can't guarantee that $x$ reduces to $e$ of the \emph{same} type $\tau$,
only that $e$ has \emph{some} type.
Type-annotated definitions in turn force locally-named expressions
in $\kw{let}$ expressions to have annotations as well.
In the congruence rule that reduces the body of a $\kw{let}$ expression,
the named expression needs to be added as a definition to the environment,
but since reduction is untyped, its type can't be derived:
it must be provided by the $\kw{let}$ expression itself.

Although not directly related to the type preservation proofs,
proving confluence requires that the notion of $\rhd^*$ be exactly the
reflexive, transitive closure of $\rhd$, so the congruence rules need to be
a part of $\rhd$ and not of $\rhd^*$ (as is the case for the languages compiled in \citet{wjb}).

Some of these constraints are not so serious:
$\kw{let}$ expressions without type annotations, for instance,
can be easily elaborated into a core calculus with annotations.
Other constraints require more work to handle:
although a variant of \lang with typed equivalence would instinctively be equivalent
to \lang without, proving that nothing has been broken by the introduction of typed equivalence
requires yet another syntactic model, which would have the same mutual induction issues.
In other words, a syntactic model constrains us to a particular presentation of the type theory
and its judgement rules, and changing the presentation (\eg for implementation in a type checker)
requires either more proof work or a certain amount of trust in the correctness of the changes.

\section{Future Directions}

There is still a long way to go towards a sized dependent type system
that is expressive, consistent, and useable.
We've seen from \cref{sec:examples} that working without an infinite size
or full inductives is verbose at best, in the case of $\msort$ and $\qsort$,
and impossible at worse, in the case of $\const{\omega}$,
while attempts at including them either involve inconsistency, undecidability, or noncanonicity.
Alternate approaches need to be investigated to circumvent these problems.

While the issue with the universe levels of inductive types appears to be cosmetic
and not affect any important significant metatheoretical properties,
it might be a mere symptom of a larger issue with how sizes are modelled,
especially since prior sized type systems shown to be consistent
haven't required any similar restrictions.
One possibility is to take inspiration from Agda and
make $\SizeT$ live in a universe $\SizeUnivT$ independent of $\TypeT{}$,
but the consistency of arbitrarily adding a new universe is questionable,
especially when $\SizeUnivT$ needs to be slightly impredicative:
$\arrT*{\TypeT{}}{\SizeT}$ would remain in $\SizeUnivT$
(as would be the case for $\limT$)
and $\funtypeT{\alpha}{\SizeT}{\N{\alpha}}$ would remain in $\TypeT{0}$
(as would be the case for $\zeroT$).

The main barrier to a syntactic model\index{syntactic model} of \lang with any coinductive types
is the lack of an established target type theory with coinductive types
with nice properties.
Whereas pCIC\index{Calculus of Inductive Constructions!Predicative \textasciitilde}
and pCuIC\index{Predicative Calculus of Cumulative Inductive Constructions} lack them,
MetaCoq\index{MetaCoq} mechanizes Coq-style coinductive types,
but necessarily cannot prove its own consistency.
Meanwhile, older CICs with coinductive types and cofixpoints guarded by constructors\index{guardedness}
(\eg \citet{guard}) have issues with subject reduction~\citep{coind-SR}\index{subject reduction},
which is a necessary property for proving type preservation\index{type preservation} in \cref{ch:proofs}.
Another potential issue is the translation of cofixpoints into applications of
a well-founded induction principle, which is suspicious and also requires further investigation.

Finally, \lang is missing some important but comparatively simple features
from the perspective of the syntactic model, namely inductive types in general.
They can be added directly to \lang as a generalization of the existing inductives,
and I conjecture that the type preservation proofs would be a straightforward extension.
Alternatively, since there already are well-founded trees,
\lang could instead be augmented with dependent pairs and an equality type,
both of which I also conjecture to be straightforward;
then mutual inductives, indexed inductives \citep{whynotW}, some nested inductives \citep{barras},
and even some inductive--inductive types \citep{ind-ind}
can be encoded, along with their induction principles, using W types and propositional equality.

\hfill

In terms of metatheory, \lang is missing proof of two desirable properties:
strong normalization and decidability of type checking.
Because \nameref{lem:pres-red} only preserves reduction up to equivalence in \CICE,
not reduction, normalization doesn't hold immediately from the translation.
In particular, the proof of \nameref{lem:pres-red} uses equality reflection
to obtain an equivalence between two proofs of accessibility\index{accessibility predicate} of a size,
and \citet{SProp} show that this equivalence can lead to nonnormalization in
particular inconsistent environments,
as is the case for $\tg{false}$.

Even so, I conjecture that translation of a \lang term will never lead to
a \CICE term with a subterm in an appropriate inconsistent environment that leads to nonnormalization,
because the translation will never yield an assumption of the form $\sT \szltT \sT$.
By inspection of the translation, the only fitting subsizing relation possible is of the form $\alphaT \szltT \alphaT$,
and the only possible sources $\Funtype<{\alpha}{\alpha}{\tau}$, $\Fun<{\alpha}{\alpha}{e}$ are ill-scoped.
Since fixpoints only reduce when applied to sizes that have a subsize
and we can't obtain infinitely decreasing chains of subsizes,
they can't unfold endlessly and must stop eventually.

Decidability of type checking, meanwhile, rests not only on strong normalization,
but also on decidability of subsizing, \ie deciding whether $\bound{r}{s}$ holds.
The trickiest rule is transitivity of subsizing,
but I conjecture that subsizing, too, is decidable,
as the size environment only contains a finite number of bounded size variables,
and sizes can only have a finite number of successor operators applied.
Moreover, Agda has transitive subsizing, and so far hasn't had issues with its decidability.

\hfill

As for implementation, the consistency of \lang shows that sized types for inductives in Agda
are likely to be consistent were the infinite size\index{infinite size} removed.
This immediately poses a significant problem to Agda's standard library,
as 20 of the 33 files that use sized types in version 1.7.1 of the standard library
make use of the infinite size.
Furthermore, 30 of those files deal with coinductives rather than inductives,
and it remains to be seen whether \lang with coinductives really is consistent as well.
The addition of the $\const{ac}$ axiom to recover some of the expressivity of the infinite size
isn't ideal for a proof assistant either, since it would block computation.

\section{Conclusion}

In this thesis, I introduced \lang, a sized dependent type theory
with higher-rank size quantification and bounded size quantification,
but without an infinite size that is strictly greater than itself,
along with sized naturals and well-founded trees.
I gave examples of programming with sized inductives to write recursive programs
that would have otherwise not passed the usual syntactic guard checks,
as well as limitations of programming without the infinite size.
I then reduced the consistency of \lang to that of \CICE,
an extensional dependent type theory, by translating \lang terms to \CICE terms
and proving that the translation is type preserving.
Finally, I discussed the tradeoffs in the design of \lang for this syntactic model to work,
namely the lack of an infinite size and raising the universe levels of the inductives,
as well as some potential extensions and future work.